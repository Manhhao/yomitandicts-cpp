#!/usr/bin/env python3
"""
Generate C++ data tables for Japanese text processors.

This script generates `unicode_data.hpp` containing:
  1. CJK Compatibility NFKD decompositions (U+3300-U+33FF)
     - Source: Python unicodedata module (Unicode standard)
  2. Kangxi Radicals NFKD decompositions (U+2F00-U+2FDF)
     - Source: Python unicodedata module (Unicode standard)
  3. CJK Radicals Supplement NFKD decompositions (U+2E80-U+2EFF)
     - Source: Python unicodedata module (Unicode standard)
  4. Kanji variant (異体字 -> 親字) mapping
     - Source: `kanji-processor` npm package (三省堂 全訳 漢辞海 第四版)
     - https://www.npmjs.com/package/kanji-processor

Usage:
    python scripts/generate_data.py

The kanji-processor data is automatically downloaded from the npm registry
if not already cached locally. No npm installation is required.
"""

import json
import unicodedata
import os
import io
import gzip
import tarfile
import urllib.request

SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_DIR = os.path.dirname(SCRIPT_DIR)
OUTPUT_DIR = os.path.join(PROJECT_DIR, "src", "text_processor")
CACHE_DIR = os.path.join(PROJECT_DIR, "tmp", "kanji-processor")

KANJI_PROCESSOR_REGISTRY_URL = "https://registry.npmjs.org/kanji-processor/latest"


def escape_u32char(cp):
    """Format a codepoint as C++ char32_t hex literal."""
    return f"0x{cp:04X}"


def escape_u32string(codepoints):
    """Format a list of codepoints as C++ U\"...\" string literal using escape sequences."""
    parts = []
    for cp in codepoints:
        if cp < 0x10000:
            parts.append(f"\\u{cp:04X}")
        else:
            parts.append(f"\\U{cp:08X}")
    return 'U"' + "".join(parts) + '"'


def generate_cjk_compat_nfkd():
    """Generate CJK Compatibility NFKD table (U+3300-U+33FF).

    Pre-computes the NFKD decompositions used at runtime by normalizeCJKCompatibilityCharacters.
    Unlike the radicals tables below, decompositions here can be multi-character (e.g. ㌀ → アパート).
    https://github.com/yomidevs/yomitan/blob/81d17d877fb18c62ba826210bf6db2b7f4d4deed/ext/js/language/ja/japanese.js#L642
    https://github.com/yomidevs/yomitan/blob/81d17d877fb18c62ba826210bf6db2b7f4d4deed/ext/js/language/CJK-util.js#L78
    """
    lines = []
    lines.append("// CJK Compatibility NFKD decompositions (U+3300 - U+33FF)")
    lines.append("// Auto-generated by scripts/generate_data.py")
    lines.append(
        "const std::unordered_map<char32_t, std::u32string> CJK_COMPAT_NFKD = {"
    )
    count = 0
    for cp in range(0x3300, 0x3400):
        c = chr(cp)
        nfkd = unicodedata.normalize("NFKD", c)
        if nfkd != c:
            codepoints = [ord(ch) for ch in nfkd]
            lines.append(f"    {{{escape_u32char(cp)}, {escape_u32string(codepoints)}}},")
            count += 1
    lines.append("};")
    print(f"  CJK Compatibility: {count} entries")
    return lines


def generate_single_char_nfkd(range_start, range_end, table_name, description):
    """Generate a char32_t → char32_t NFKD mapping table for a Unicode range.

    Only includes codepoints whose NFKD decomposition is a single character.
    """
    lines = []
    lines.append(f"// {description}")
    lines.append("// Auto-generated by scripts/generate_data.py")
    lines.append(
        f"const std::unordered_map<char32_t, char32_t> {table_name} = {{"
    )
    count = 0
    for cp in range(range_start, range_end + 1):
        c = chr(cp)
        nfkd = unicodedata.normalize("NFKD", c)
        if nfkd != c and len(nfkd) == 1:
            lines.append(f"    {{{escape_u32char(cp)}, {escape_u32char(ord(nfkd))}}},")
            count += 1
    lines.append("};")
    return lines, count


def generate_kangxi_radicals_nfkd():
    """Generate Kangxi Radicals NFKD table (U+2F00-U+2FDF).

    Pre-computes the NFKD decompositions used at runtime by normalizeRadicals.
    https://github.com/yomidevs/yomitan/blob/81d17d877fb18c62ba826210bf6db2b7f4d4deed/ext/js/language/CJK-util.js#L104
    https://github.com/yomidevs/yomitan/blob/81d17d877fb18c62ba826210bf6db2b7f4d4deed/ext/js/language/CJK-util.js#L123

    Note: CJK_STROKES_RANGE (U+31C0-U+31EF) is also part of CJK_RADICALS_RANGES
    but has no NFKD decompositions in Unicode, so no table is generated for it.
    https://github.com/yomidevs/yomitan/blob/81d17d877fb18c62ba826210bf6db2b7f4d4deed/ext/js/language/CJK-util.js#L110
    """
    lines, count = generate_single_char_nfkd(
        0x2F00, 0x2FDF,
        "KANGXI_RADICALS_NFKD",
        "Kangxi Radicals NFKD decompositions (U+2F00 - U+2FDF)",
    )
    print(f"  Kangxi Radicals: {count} entries")
    return lines


def generate_cjk_radicals_supplement_nfkd():
    """Generate CJK Radicals Supplement NFKD table (U+2E80-U+2EFF).

    Pre-computes the NFKD decompositions used at runtime by normalizeRadicals.
    https://github.com/yomidevs/yomitan/blob/81d17d877fb18c62ba826210bf6db2b7f4d4deed/ext/js/language/CJK-util.js#L107
    https://github.com/yomidevs/yomitan/blob/81d17d877fb18c62ba826210bf6db2b7f4d4deed/ext/js/language/CJK-util.js#L123
    """
    lines, count = generate_single_char_nfkd(
        0x2E80, 0x2EFF,
        "CJK_RADICALS_SUPPLEMENT_NFKD",
        "CJK Radicals Supplement NFKD decompositions (U+2E80 - U+2EFF)",
    )
    print(f"  CJK Radicals Supplement: {count} entries")
    return lines


def fetch_kanji_processor_data():
    """
    Download and extract full_list.json from the kanji-processor npm package.

    Uses the npm registry REST API to fetch the tarball directly, without
    requiring npm to be installed. The extracted data is cached locally in
    tmp/kanji-processor/ so subsequent runs don't need to re-download.

    Data source: https://www.npmjs.com/package/kanji-processor
    Referenced as a dependency in yomitan:
    https://github.com/yomidevs/yomitan/blob/81d17d877fb18c62ba826210bf6db2b7f4d4deed/package.json#L120

    Returns the path to full_list.json.
    """
    cached_path = os.path.join(CACHE_DIR, "full_list.json")
    if os.path.exists(cached_path):
        print(f"  Using cached kanji-processor data: {cached_path}")
        return cached_path

    print("  Downloading kanji-processor from npm registry...")

    # Step 1: Get the package metadata to find the tarball URL
    req = urllib.request.Request(
        KANJI_PROCESSOR_REGISTRY_URL,
        headers={"Accept": "application/json"},
    )
    with urllib.request.urlopen(req) as resp:
        meta = json.loads(resp.read().decode("utf-8"))
    tarball_url = meta["dist"]["tarball"]
    version = meta["version"]
    print(f"  Found kanji-processor v{version}")
    print(f"  Tarball URL: {tarball_url}")

    # Step 2: Download and extract the tarball
    with urllib.request.urlopen(tarball_url) as resp:
        tarball_data = resp.read()

    # npm tarballs are gzipped
    with gzip.open(io.BytesIO(tarball_data)) as gz:
        with tarfile.open(fileobj=gz, mode="r:") as tar:
            # Look for dist/full_list.json inside the tarball
            target_name = None
            for member in tar.getmembers():
                if member.name.endswith("dist/full_list.json"):
                    target_name = member.name
                    break

            if target_name is None:
                raise FileNotFoundError(
                    "dist/full_list.json not found in kanji-processor tarball"
                )

            f = tar.extractfile(target_name)
            if f is None:
                raise FileNotFoundError(
                    f"Could not extract {target_name} from tarball"
                )
            data = f.read()

    # Step 3: Cache the extracted file
    os.makedirs(CACHE_DIR, exist_ok=True)
    with open(cached_path, "wb") as out:
        out.write(data)

    print(f"  Cached to {cached_path}")
    return cached_path


def generate_kanji_variants():
    """Generate kanji variant (itaiji -> oyaji) mapping from kanji-processor data.

    Pre-computes the variant mapping used at runtime by convertVariants / standardizeKanji.
    https://github.com/yomidevs/yomitan/blob/81d17d877fb18c62ba826210bf6db2b7f4d4deed/ext/js/language/ja/japanese-text-preprocessors.js#L30
    https://github.com/yomidevs/yomitan/blob/81d17d877fb18c62ba826210bf6db2b7f4d4deed/ext/js/language/ja/japanese-text-preprocessors.js#L113
    """
    json_path = fetch_kanji_processor_data()
    with open(json_path, "r", encoding="utf-8") as f:
        full_list = json.load(f)

    lines = []
    lines.append("// Kanji variant (異体字 -> 親字) mapping")
    lines.append("// Source: kanji-processor npm package (三省堂 全訳 漢辞海 第四版)")
    lines.append("// Auto-generated by scripts/generate_data.py")
    lines.append(
        "const std::unordered_map<char32_t, char32_t> KANJI_VARIANTS = {"
    )
    count = 0
    for entry in full_list:
        oyaji = entry["oyaji"]
        oyaji_cp = ord(oyaji)
        for itaiji in entry["itaiji"]:
            itaiji_cp = ord(itaiji)
            lines.append(f"    {{{escape_u32char(itaiji_cp)}, {escape_u32char(oyaji_cp)}}},")
            count += 1
    lines.append("};")
    print(f"  Kanji Variants: {count} entries")
    return lines


def main():
    print("Generating C++ data tables...")

    all_lines = []
    all_lines.append("#pragma once")
    all_lines.append("")
    all_lines.append("// Auto-generated Unicode data tables for Japanese text processing")
    all_lines.append("// Generated by scripts/generate_data.py")
    all_lines.append("// Do not edit manually.")
    all_lines.append("")
    all_lines.append("#include <string>")
    all_lines.append("#include <unordered_map>")
    all_lines.append("")

    all_lines.extend(generate_cjk_compat_nfkd())
    all_lines.append("")
    all_lines.extend(generate_kangxi_radicals_nfkd())
    all_lines.append("")
    all_lines.extend(generate_cjk_radicals_supplement_nfkd())
    all_lines.append("")
    all_lines.extend(generate_kanji_variants())
    all_lines.append("")

    output_path = os.path.join(OUTPUT_DIR, "unicode_data.hpp")
    with open(output_path, "w", encoding="utf-8") as f:
        f.write("\n".join(all_lines))

    print(f"Written to {output_path}")


if __name__ == "__main__":
    main()
